import time
import streamlit as st
import asyncio
import sys
import datetime
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

from scraper import DuckDuckGoScraper,create_download_files, display_error_suggestions, display_no_results_info

def _add_normal_query(queries, query_parts):
    if queries.get('normal_query'):
        query_parts.append(queries['normal_query'])

def _add_exact_phrase(queries, query_parts):
    if queries.get('exact_phrase'):
        query_parts.append(f'"{queries["exact_phrase"]}"')

def _add_semantic_query(queries, query_parts):
    if queries.get('semantic_query'):
        query_parts.append(f'~"{queries["semantic_query"]}"')

def _add_include_terms(queries, query_parts):
    if queries.get('include_terms'):
        terms = [term.strip() for term in queries['include_terms'].split(',') if term.strip()]
        query_parts.extend([f"+{term}" for term in terms])

def _add_exclude_terms(queries, query_parts):
    if queries.get('exclude_terms'):
        terms = [term.strip() for term in queries['exclude_terms'].split(',') if term.strip()]
        query_parts.extend([f"-{term}" for term in terms])

def _add_filetype(queries, query_parts):
    if queries.get('filetype'):
        query_parts.append(f"filetype:{queries['filetype']}")

def _add_site_include(queries, query_parts):
    if queries.get('site_include'):
        query_parts.append(f"site:{queries['site_include']}")

def _add_site_exclude(queries, query_parts):
    if queries.get('site_exclude'):
        query_parts.append(f"-site:{queries['site_exclude']}")

def _add_intitle(queries, query_parts):
    if queries.get('intitle'):
        query_parts.append(f"intitle:{queries['intitle']}")

def _add_inurl(queries, query_parts):
    if queries.get('inurl'):
        query_parts.append(f"inurl:{queries['inurl']}")

def build_advanced_query(queries):
    """Build advanced search query with multiple query types."""
    query_parts = []
    _add_normal_query(queries, query_parts)
    _add_exact_phrase(queries, query_parts)
    _add_semantic_query(queries, query_parts)
    _add_include_terms(queries, query_parts)
    _add_exclude_terms(queries, query_parts)
    _add_filetype(queries, query_parts)
    _add_site_include(queries, query_parts)
    _add_site_exclude(queries, query_parts)
    _add_intitle(queries, query_parts)
    _add_inurl(queries, query_parts)
    return " ".join(query_parts)

def display_results(df, pages_retrieved):
    """Display the search results and download buttons."""
    if df.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏î ‡πÜ")
        display_no_results_info()
    else:
        st.success(f"‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏à‡∏≤‡∏Å {pages_retrieved} ‡∏´‡∏ô‡πâ‡∏≤")
        st.dataframe(df, use_container_width=True)
        csv_data, excel_data = create_download_files(df)
        timestamp = int(time.time())
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", 
                data=csv_data, 
                file_name=f"ddg_{timestamp}.csv",
                mime="text/csv"
            )
        with col2:
            st.download_button(
                "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel", 
                data=excel_data, 
                file_name=f"ddg_{timestamp}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

def main():
    """Main Streamlit application with progress tracking."""
    st.set_page_config(page_title="ü¶Ü DuckDuckGo Scraper", layout="wide")
    st.title("ü¶Ü DuckDuckGo Advanced Scraper")
    st.markdown("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å Search ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")

    # Initialize session state
    if 'search_results' not in st.session_state:
        st.session_state.search_results = None
    if 'pages_retrieved' not in st.session_state:
        st.session_state.pages_retrieved = 0
    if 'last_query' not in st.session_state:
        st.session_state.last_query = ""
    if 'final_query_used' not in st.session_state:
        st.session_state.final_query_used = ""

    # ...existing sidebar and input code remains the same...
    # Sidebar configuration
    st.sidebar.header("‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Scraper")
    max_pages = st.sidebar.number_input(
        "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤", 
        min_value=1, 
        value=20, 
        step=1,
        help="‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏ñ‡∏π‡∏Å‡∏ö‡∏•‡πá‡∏≠‡∏Å"
    )

    if max_pages > 100:
        st.sidebar.warning("‚ö†Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏≤‡∏Å ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î")

    # Date range filter in sidebar
    st.sidebar.header("üìÖ ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà")
    use_date_filter = st.sidebar.checkbox("‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", help="‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î")
    
    start_date = None
    end_date = None
    
    if use_date_filter:
        col1, col2 = st.sidebar.columns(2)
        with col1:
            start_date = st.date_input(
                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô:",
                value=datetime.date.today() - datetime.timedelta(days=30),
                help="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤"
            )
        with col2:
            end_date = st.date_input(
                "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î:",
                value=datetime.date.today(),
                help="‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤"
            )
        
        if start_date and end_date:
            if start_date > end_date:
                st.sidebar.error("‚ùå ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
            else:
                st.sidebar.success(f"üìÖ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")

    # Main search inputs
    st.header("üîç ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
    
    col1, col2 = st.columns(2)
    
    with col1:
        normal_query = st.text_input(
            "‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ:",
            placeholder="‡πÄ‡∏ä‡πà‡∏ô artificial intelligence",
            help="‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏õ‡∏Å‡∏ï‡∏¥ - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡πÉ‡∏î‡∏Ñ‡∏≥‡∏´‡∏ô‡∏∂‡πà‡∏á"
        )
        
        semantic_query = st.text_input(
            "‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö Semantic (~):",
            placeholder="‡πÄ‡∏ä‡πà‡∏ô machine learning",
            help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"
        )
    
    with col2:
        exact_phrase = st.text_input(
            "‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (\"):",
            placeholder="‡πÄ‡∏ä‡πà‡∏ô data science",
            help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ß‡∏•‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô"
        )

    # Advanced search options in sidebar
    st.sidebar.header("üîß ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á")
    
    # Include/Exclude terms
    include_terms = st.sidebar.text_input(
        "‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ô‡πâ‡∏ô (+):",
        placeholder="python, tutorial",
        help="‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡πâ‡∏ô‡πÉ‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
    )
    
    exclude_terms = st.sidebar.text_input(
        "‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô (-):",
        placeholder="basic, beginner",
        help="‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
    )
    
    # File type filter
    filetype = st.sidebar.selectbox(
        "‡∏ä‡∏ô‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå:",
        ["", "pdf", "doc", "docx", "xls", "xlsx", "ppt", "pptx", "html"],
        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"
    )
    
    # Site filters
    site_include = st.sidebar.text_input(
        "‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (site:):",
        placeholder="arxiv.org",
        help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ô‡∏µ‡πâ"
    )
    
    site_exclude = st.sidebar.text_input(
        "‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå (-site:):",
        placeholder="wikipedia.org",
        help="‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ô‡∏µ‡πâ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
    )
    
    # Title and URL filters
    intitle = st.sidebar.text_input(
        "‡πÉ‡∏ô Title (intitle:):",
        placeholder="research",
        help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö"
    )
    
    inurl = st.sidebar.text_input(
        "‡πÉ‡∏ô URL (inurl:):",
        placeholder="blog",
        help="‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡πÉ‡∏ô URL ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö"
    )

    # Build queries dict
    queries = {
        'normal_query': normal_query,
        'exact_phrase': exact_phrase,
        'semantic_query': semantic_query,
        'include_terms': include_terms,
        'exclude_terms': exclude_terms,
        'filetype': filetype,
        'site_include': site_include,
        'site_exclude': site_exclude,
        'intitle': intitle,
        'inurl': inurl
    }
    
    # Build final query
    final_query = build_advanced_query(queries)
    
    # Display the constructed query
    if final_query:
        query_display = f"**‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ:** `{final_query}`"
        if use_date_filter and start_date and end_date:
            query_display += f"\nüìÖ **‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:** {start_date} ‡∏ñ‡∏∂‡∏á {end_date}"
        st.info(query_display)
    
    # Validation
    has_any_query = any([normal_query.strip(), exact_phrase.strip(), semantic_query.strip()])
    
    # Clear previous results if query changed
    query_key = f"{final_query}_{start_date}_{end_date}" if use_date_filter else final_query
    if query_key != st.session_state.last_query and final_query.strip():
        st.session_state.search_results = None
        st.session_state.pages_retrieved = 0
    
    if st.button("Search", type="primary"):
        if not has_any_query:
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å Search")
            return
        
        if use_date_filter and start_date and end_date and start_date > end_date:
            st.error("‚ùå ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î")
            return

        scraper = DuckDuckGoScraper()
        
        # Create progress tracking containers
        progress_container = st.container()
        
        with progress_container:
            # Progress bar
            progress_bar = st.progress(0)
            
            # Status text
            status_text = st.empty()
            
            # Progress details
            progress_details = st.empty()
            
            # Progress callback function
            def update_progress(current_page, max_pages, status_message):
                # Calculate progress percentage
                if max_pages > 0:
                    progress = min(current_page / max_pages, 1.0)
                else:
                    progress = 0
                
                # Update progress bar
                progress_bar.progress(progress)
                
                # Update status text
                status_text.info(f"üìÑ ‡∏´‡∏ô‡πâ‡∏≤ {current_page}/{max_pages} - {status_message}")
                
                # Update detailed progress
                with progress_details.container():
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô", current_page)
                    with col2:
                        st.metric("‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", max_pages)
                    with col3:
                        st.metric("‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå", f"{progress * 100:.1f}%")
                
                # Force update the display
                time.sleep(0.1)
        
        try:
            # Convert dates to string format if date filter is enabled
            start_date_str = start_date.strftime('%Y-%m-%d') if use_date_filter and start_date else None
            end_date_str = end_date.strftime('%Y-%m-%d') if use_date_filter and end_date else None
            
            df, pages_retrieved = scraper.scrape(
                final_query, 
                max_pages, 
                headless=True, 
                progress_callback=update_progress,
                start_date=start_date_str,
                end_date=end_date_str
            )
            
            # Clear progress indicators
            progress_container.empty()
            
            st.session_state.search_results = df
            st.session_state.pages_retrieved = pages_retrieved
            st.session_state.last_query = query_key
            st.session_state.final_query_used = final_query
            
        except Exception as e:
            # Clear progress indicators
            progress_container.empty()
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πÅ‡∏Ñ‡∏£‡∏õ: {str(e)}")
            display_error_suggestions()
            return

    # Display results if they exist in session state
    if st.session_state.search_results is not None:
        df = st.session_state.search_results
        pages_retrieved = st.session_state.pages_retrieved
        display_results(df, pages_retrieved)


if __name__ == "__main__":
    main()