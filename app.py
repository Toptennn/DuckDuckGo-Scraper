import time
import streamlit as st
import asyncio
import sys
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

from scraper import DuckDuckGoScraper,create_download_files, display_error_suggestions, display_no_results_info

def display_results(df, pages_retrieved, max_pages):
    """Display the search results and download buttons."""
    if df.empty:
        st.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏î ‡πÜ")
        display_no_results_info()
    else:
        st.success(f"‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡∏à‡∏≤‡∏Å {pages_retrieved} ‡∏´‡∏ô‡πâ‡∏≤")
        if pages_retrieved < max_pages:
            st.info(f"‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Scraping ‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á {pages_retrieved} ‡∏´‡∏ô‡πâ‡∏≤ ‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ {max_pages} ‡∏´‡∏ô‡πâ‡∏≤")
        st.dataframe(df, use_container_width=True)
        csv_data, excel_data = create_download_files(df)
        timestamp = int(time.time())
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV", 
                data=csv_data, 
                file_name=f"ddg_{timestamp}.csv",
                mime="text/csv"
            )
        with col2:
            st.download_button(
                "‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Excel", 
                data=excel_data, 
                file_name=f"ddg_{timestamp}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

def main():
    """Main Streamlit application."""
    st.set_page_config(page_title="ü¶Ü DuckDuckGo Scraper", layout="wide")
    st.title("ü¶Ü DuckDuckGo Playwright Scraper")
    st.markdown("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å Search ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")

    # Initialize session state
    if 'search_results' not in st.session_state:
        st.session_state.search_results = None
    if 'pages_retrieved' not in st.session_state:
        st.session_state.pages_retrieved = 0
    if 'last_query' not in st.session_state:
        st.session_state.last_query = ""

    # Sidebar configuration
    st.sidebar.header("‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Scraper")
    max_pages = st.sidebar.slider("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤", 1, 100, 20)

    # Main input
    query = st.text_input(
        "üîç ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:", 
        value="", 
        placeholder="‡πÄ‡∏ä‡πà‡∏ô artificial intelligence"
    )
    
    # Clear previous results if query changed
    if query != st.session_state.last_query and query.strip():
        st.session_state.search_results = None
        st.session_state.pages_retrieved = 0
    
    if st.button("Search"):
        if not query.strip():
            st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏Å Search")
            return

        scraper = DuckDuckGoScraper()
        
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤... ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"):
            try:
                df, pages_retrieved = scraper.scrape(query, max_pages, headless=True)
                # Store results in session state
                st.session_state.search_results = df
                st.session_state.pages_retrieved = pages_retrieved
                st.session_state.last_query = query
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πÅ‡∏Ñ‡∏£‡∏õ: {e}")
                display_error_suggestions()
                return

    # Display results if they exist in session state
    if st.session_state.search_results is not None:
        df = st.session_state.search_results
        pages_retrieved = st.session_state.pages_retrieved
        display_results(df, pages_retrieved, max_pages)


if __name__ == "__main__":
    main()